# -*- coding: utf-8 -*-
"""Ujian Modul 3 - Kharisma Satrio

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16ZN9q1SidFsFRP4dkgJwXMwgLuidqHOk

#Problem Framing

##Business Objective

Memprediksi sebuah pattern costumer yang akan membatalkan pesanan berdasarkan dataset informasi pemesanan kamar hotel

##Output dan manfaat yang di inginkan stakeholder

Machine learning yang dapat mengidentifikasi costumer yang akan membatalkan pesanan penginapan

manfaat: Untuk mengoptimalkan pendapatan dan mencegah terjadinya kerugian akibat pembatalan pesanan

##Machine Learning yang akan dikerjakan
"""

Machine learning yang akan dikerjakan adalah machine learning supervised dikarenakan terdapat label yang telah diberikan oleh data set dan objectifnya adalah memprediksi label tersebut

"""##Performance measure yang digunakan"""

Performance yang digunakan adalah accuracy score, dikarenakan kita ingin membuat model yang reliable untuk memprediksi label

"""##Risiko apa yang akan di sebabkan"""

Resiko yang mungkin akan disebabkan adalah terjadi false type 1 & false type 2 error dalam memprediksi label

"""#EDA

##Import Dataset
"""

from google.colab import files
files.upload()

import pandas as pd

hotel_booking = pd.read_csv('hotel_bookings.csv')

hotel_booking.head()

"""##Cleaning Data"""

hotel_booking.isnull().sum()

hotel_booking.dtypes

#Diketahui terdapat missing data pada beberapa data tersebut, sehingga data yang kosong kita isi dengan 0
nan_impute = {"children:": 0.0,"country": "Unknown", "agent": 0, "company": 0}
hotel_booking_cleaned = hotel_booking.fillna(nan_impute)

#Diketahui terdapat kombinasi dimana terdapat jumlah tamu 0, sehingga data tersebut menjadi invalid maka kita akan drop data tersebut
zero_guest_index = hotel_booking_cleaned[(hotel_booking_cleaned['adults'] == 0) & (hotel_booking_cleaned['children'] == 0) & (hotel_booking_cleaned['babies'] == 0)].index
hotel_booking_cleaned.drop(hotel_booking_cleaned.index[zero_guest_index],inplace=True)

"""Graph The Dataset"""

import matplotlib.pyplot as plt
import seaborn as sns

hotel_booking_cleaned

plt.figure()
sns.countplot(hotel_booking_cleaned['is_canceled'],hue=hotel_booking_cleaned['hotel'])
#Disini terlihat majority terbesar pesanan yang di cancel berada pada City Hotel, bahkan hingga melebihi total booking yang tidak dicancel pada Resort hotel

hotel_booking_cleaned['is_canceled'].value_counts()

plt.figure()
sns.countplot(hotel_booking_cleaned['is_canceled'],hue=hotel_booking_cleaned['is_repeated_guest'])
#Disini terlihat bahwa repeated guest majoritas tidak mengcancel booking order mereka

plt.figure(figsize=(15,5))
plt.hist(hotel_booking_cleaned['arrival_date_month'])
plt.show()
#Disini terlihat bahwa bulan juli dan agustus juga bulan may dan juni merupakan bulan-bulan dimana demand terbesar terjadi

hotel_booking_cleaned['adr'] = hotel_booking_cleaned['adr'].astype(float)
plt.figure(figsize=(15,5))
sns.barplot(hotel_booking_cleaned['arrival_date_month'], hotel_booking_cleaned['adr'],hue=hotel_booking_cleaned['is_canceled'])
plt.title('Arrival month vs Adr vs Booking cancalled status')
plt.show()
#disini menunjukkan relasi antar Arrival Daily Rate dengan arrival month, pada bulan-bulan dengan demand tertinggi kecuali agustus dan juli booking cancelation mempunya adr yang lebih rendah dibanding cancel booking = false, mungkin ini menandakan bahwa ADR merupakan salah satu alasan booking di cancel

order=hotel_booking_cleaned['country'].value_counts().iloc[:10]

plt.figure()
sns.countplot(hotel_booking_cleaned['country'], order=hotel_booking_cleaned['country'].value_counts().iloc[:10].index)
plt.title('Top 10 country Origin')
plt.xlabel('County')
plt.show()
#Disini terlihat 10 negara yang paling banyak menjad costumer

plt.figure(figsize=(10,5))
sns.countplot(hotel_booking_cleaned['market_segment'], order=hotel_booking_cleaned['market_segment'].value_counts().iloc[:10].index)
plt.title('Type Market Segment')
plt.xlabel('Market Segment')
plt.show()

"""#Data Prepration"""

cancel_corr = hotel_booking_cleaned.corr()["is_canceled"]
cancel_corr.abs().sort_values(ascending=False)
#Disini terlihat 5 feature terpenting dan feature yang harus dikeluarkan adalah reservation_status
#Dan untuk mencegah data leakage maka arrival_date_year, assigned_room_type, booking_changes, reservation_status, country, days_in_waitingtidak akan di include

hotel_booking_cleaned.shape

#Numeric Feature
num_features = ["lead_time","arrival_date_week_number","arrival_date_day_of_month",
                "stays_in_weekend_nights","stays_in_week_nights","adults","children",
                "babies","is_repeated_guest", "previous_cancellations",
                "previous_bookings_not_canceled","agent","company",
                "required_car_parking_spaces", "total_of_special_requests", "adr"]

#Categorical Feature
cat_features = ["hotel","arrival_date_month","meal","market_segment",
                "distribution_channel","reserved_room_type","deposit_type","customer_type"]

#Seperate feature dan label
features = num_features + cat_features
X = hotel_booking_cleaned.drop(['is_canceled'],axis=1)[features]
y = hotel_booking_cleaned['is_canceled']

from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

#Preprocessing Categorical feature
cat_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="constant", fill_value="Unknown")),
    ("onehot", OneHotEncoder(handle_unknown='ignore'))])

#Column Transform
preprocessor = ColumnTransformer(transformers=[("cat", cat_transformer, cat_features)])

"""#Model Training"""

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold

split = StratifiedKFold(n_splits = 5,shuffle=True,random_state=42)

"""##Decision Tree"""

from sklearn.tree import DecisionTreeClassifier

tree = DecisionTreeClassifier(random_state=42)

model_steps = Pipeline(steps=[('preprocessor', preprocessor),
                              ('tree', tree)])

cv_results = cross_val_score(model_steps, 
                                 X, y, 
                                 cv=split,
                                 scoring="accuracy",
                                 n_jobs=-1)

min_score = round(min(cv_results), 4)
max_score = round(max(cv_results), 4)
mean_score = round(np.mean(cv_results), 4)
std_dev = round(np.std(cv_results), 4)
print(f" cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}")

"""##Random Forest"""

from sklearn.ensemble import RandomForestClassifier

random_forest = RandomForestClassifier(random_state=42,n_jobs=-1)

model_steps = Pipeline(steps=[('preprocessor', preprocessor),
                              ('random_forest', random_forest)])

cv_results = cross_val_score(model_steps, 
                                 X, y, 
                                 cv=split,
                                 scoring="accuracy",
                                 n_jobs=-1)

min_score = round(min(cv_results), 4)
max_score = round(max(cv_results), 4)
mean_score = round(np.mean(cv_results), 4)
std_dev = round(np.std(cv_results), 4)
print(f" cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}")

"""##XGB"""

from xgboost import XGBClassifier

XGB = XGBClassifier(random_state=42, n_jobs=-1)

model_steps = Pipeline(steps=[('preprocessor', preprocessor),
                              ('XGB', XGB)])

min_score = round(min(cv_results), 4)
max_score = round(max(cv_results), 4)
mean_score = round(np.mean(cv_results), 4)
std_dev = round(np.std(cv_results), 4)
print(f" cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}")

"""Best model yang dipilih adalah random forest/ XGB

#Evaluation, Model Selection and Model Tuning
"""

rf_model_enh = RandomForestClassifier(n_estimators=160,
                               max_features=0.4,
                               min_samples_split=2,
                               n_jobs=-1,
                               random_state=0)

split = StratifiedKFold(n_splits = 5,shuffle=True,random_state=42)
model_pipe = Pipeline(steps=[('preprocessor', preprocessor),
                              ('model', rf_model_enh)])
cv_results = cross_val_score(model_pipe, 
                                 X, y, 
                                 cv=split,
                                 scoring="accuracy",
                                 n_jobs=-1)
# output:
min_score = round(min(cv_results), 4)
max_score = round(max(cv_results), 4)
mean_score = round(np.mean(cv_results), 4)
std_dev = round(np.std(cv_results), 4)
print(f"Enhanced RF model cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}")

"""#Result Conclusion and Recomendation

Kesimpulannya memprediksi dengan menggunakan  random forest merupakan pilihan terbaik dan random forest dapat di tingkatkan nilai akurasi dengan memainkan parameter pada estimator tersebut
"""